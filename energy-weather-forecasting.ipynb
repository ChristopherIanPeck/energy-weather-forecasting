{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3032612,"sourceType":"datasetVersion","datasetId":1854875},{"sourceId":10401017,"sourceType":"datasetVersion","datasetId":6444667}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Predicting Electricity Spot Prices Based on Weather Patterns in Nordic Countries**","metadata":{}},{"cell_type":"markdown","source":"In this project, I will combine weather, electricity spot price and energy productionn and consumption data for Norway in the perido of 2017-2019.\n\nhttps://www.statnett.no/en/\nhttps://www.ncdc.noaa.gov/cdo-web/\nhttps://www.energidataservice.dk/tso-electricity/Elspotprices","metadata":{}},{"cell_type":"code","source":"#Set up and Libaries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nimport plotly.express as px\n\nprint(\"Libaries imported\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Loading Data\nweather_df = pd.read_csv('/kaggle/input/finland-norway-and-sweden-weather-data-20152019/nordics_weather.csv')\nelectricity_df = pd.read_csv('/kaggle/input/electricity-spot-price/Elspotprices.csv', delimiter=';')\n\n# List of production and consumption CSV files.\nproduction_consumption_files = ['/kaggle/input/production-and-consumption2017-2019/ProductionConsumption-2017.csv', \n                                '/kaggle/input/production-and-consumption2017-2019/ProductionConsumption-2018.csv', \n                                '/kaggle/input/production-and-consumption2017-2019/ProductionConsumption-2019.csv']\n\n# Read production and comsumption CSV files into dataframes and concatenate them together.\ndfs = [pd.read_csv(file, delimiter=';') for file in production_consumption_files]\nproduction_consumption_df = pd.concat(dfs, ignore_index=True)\n\nprint(\"Datasets Loaded\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Basic exploration\nprint(weather_df.head())\nprint(weather_df.dtypes)\nprint(weather_df.isnull().sum())\n\nprint(electricity_df.head())\nprint(electricity_df.dtypes)\nprint(electricity_df.isnull().sum())\n\nprint(production_consumption_df.head())\nprint(production_consumption_df .dtypes)\nprint(production_consumption_df .isnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Based on the inital exploration of the datasets, we can see there are no missing values but the data structure needs to be cleaned and parsed correctly and the time zones need to be aligned.\n\nWeather Data:\nThere are no missing values and the data appears to be clean.\n\nThe 'date' column is currently type 'object', which needs to be converted to 'datetime' and set as the index. This will allow for easier time series analysis and aslignment with the other datasets.\n\nElectricity Spot Price Data:\nTherer are no missing values but the dataset requires some cleaning.\n\nThe dataframe formatting means we need to load the data with a delimiter ';'\n\nI will remove the 'SpotPriceDKK', 'HourDK' and 'PriceArea' columns due to redudency.\n\nThe 'SpotPriceEUR' column has commas not dots in the decimal place, this will cause issues when convering them to numerical values. These converted to 'float'.\n\nThe 'HourUTC'column is a strings, which need to be converted to 'datetime' for time-based analysis just like our other datasets. I will set 'HourUTC' as the index.\n\nProduction and Conmsumption Data: ---\nThe dataframe formatting means we need to load the data with a delimiter ';'\nI also need to specify the correct formating for the date and time before converting to datetime and setting it the index.\n","metadata":{}},{"cell_type":"code","source":"#Clean Weather Dataset\n\n# Covert 'date' to 'datetime' and set 'date' as index\nweather_df['date'] = pd.to_datetime(weather_df['date'])\nweather_df.set_index('date', inplace=True)\n\nprint(weather_df.head())\nprint(weather_df.dtypes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Clean Electricity Spot Price Dataset\n\n# Convert the 'HourUTC' column to datetime\nelectricity_df['HourUTC'] = pd.to_datetime(electricity_df['HourUTC'])\n\n# Set 'HourUTC' as index for the electricity data\nelectricity_df.set_index('HourUTC', inplace=True)\n\n# Drop the redundant columns 'SpotPriceDKK' and 'TimeDKK'\nelectricity_df = electricity_df.drop(columns=['SpotPriceDKK', 'HourDK', 'PriceArea'])\n\n\nprint(electricity_df.head())\nprint(electricity_df.dtypes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Clean Production and Consumption Dataset\n\n# Convert 'Time' to datetime without timezone information\nproduction_consumption_df['Time'] = pd.to_datetime(production_consumption_df['Time'])\n\n# 3. Set 'Time' as index\nproduction_consumption_df.set_index('Time', inplace=True)\n\n# Display the first few rows and the data types\nprint(production_consumption_df.head())\nprint(production_consumption_df.dtypes)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There is an overlaping time frame from 2017 to 2019 which will be where I merge the datasets for futher analysis and filter the weather dataset for Norway specificly.","metadata":{}},{"cell_type":"code","source":"# Filter the datasets to match the time range of (2017-2019)\nweather_df_filtered = weather_df[\n    (weather_df.index >= '2017-01-01') & (weather_df.index <= '2019-12-31') & (weather_df['country'] == 'Norway')\n]\nelectricity_df_filtered = electricity_df[\n    (electricity_df.index >= '2017-01-01') & (electricity_df.index <= '2019-12-31')\n]\nproduction_consumption_df_filtered = production_consumption_df[\n    (production_consumption_df.index >= '2017-01-01') & (production_consumption_df.index <= '2019-12-31')\n]\n\n# Merge electricity and weather data\nmerged_df_1 = pd.merge(\n    electricity_df_filtered, \n    weather_df_filtered, \n    left_on='HourUTC', \n    right_index=True, \n    how='inner'\n)\n\n# Merge the result with production_consumption_df\nmerged_df = pd.merge(\n    merged_df_1, \n    production_consumption_df_filtered, \n    left_on='HourUTC', \n    right_index=True, \n    how='inner'\n)\n\n# Remove duplicates (if any)\nmerged_df = merged_df.drop_duplicates()\n\n# Reset the index for easier manipulation\nmerged_df.reset_index(inplace=True)\n\n# Display the first few rows of the merged dataframe\nprint(merged_df.head())\nprint(merged_df.dtypes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#Outliers\n\nDue to the nature of spot price and to some exten production and consumption it would be benefitial to look for outliers that could skew the data in futher analysis.\n","metadata":{}},{"cell_type":"code","source":"#Boxplot of Spotprice to check for outliers\nplt.figure(figsize=(10, 6))\nsns.boxplot(x=merged_df['SpotPriceEUR'])\nplt.title(\"Boxplot of Electricity Spot Prices\")\nplt.show()\n\n#Using IQR to verify the results from the inital Boxpot\nQ1 = merged_df['SpotPriceEUR'].quantile(0.25)\nQ3 = merged_df['SpotPriceEUR'].quantile(0.75)\nIQR = Q3 - Q1\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\noutliers = merged_df[(merged_df['SpotPriceEUR'] < lower_bound) | (merged_df['SpotPriceEUR'] > upper_bound)]\nprint(outliers)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Based on the initial results from the boxplot and IQR. There are some outliers / anomalies that need more investigation. Initially I want to check the negative values in the spot price against the production and consumption values to see if these values are realistic of over production / under consumption or if they are indeed an outliers / anomalies.","metadata":{}},{"cell_type":"code","source":"# Filter for negative spot prices\nnegative_prices = merged_df[merged_df['SpotPriceEUR'] < 0]\n\n# Plot Spot Price vs Production\nplt.figure(figsize=(10, 6))\nplt.scatter(negative_prices['Production'], negative_prices['SpotPriceEUR'], color='blue', alpha=0.6, label=\"Negative Spot Prices\")\nplt.xlabel('Production (MW)', fontsize=12)\nplt.ylabel('Spot Price (EUR)', fontsize=12)\nplt.title('Negative Spot Prices vs Production', fontsize=14)\nplt.axhline(0, color='red', linestyle='--', label='Spot Price = 0')\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.show()\n\n# Plot Spot Price vs Consumption\nplt.figure(figsize=(10, 6))\nplt.scatter(negative_prices['Consumption'], negative_prices['SpotPriceEUR'], color='green', alpha=0.6, label=\"Negative Spot Prices\")\nplt.xlabel('Consumption (MW)', fontsize=12)\nplt.ylabel('Spot Price (EUR)', fontsize=12)\nplt.title('Negative Spot Prices vs Consumption', fontsize=14)\nplt.axhline(0, color='red', linestyle='--', label='Spot Price = 0')\nplt.legend()\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Spot Price vs. Production:\nThere is a pattern where the negative spot prices are associated with production levels. These negative prices seem to occur when production is higher. This could indicate an oversupply of electricity, leading to a reduction in prices (potentially even negative values) as producers might be paid to offload excess electricity.\n\nSpot Price vs. Consumption:\nHowever negative spot prices also seem to correlate with higher consumption levels. For both high production and high consumption to be associated with negative spot prices, this does seem unusual. Typically, negative electricity prices can occur when there is an oversupply relative to demand. \n\nDue to both production and consumption being high and the spot price is still negative, it could indicate a recording error or an anomaly. To gte more information I will cross-check the values for boither the production and consumption where these negative prices are reconrded.","metadata":{}},{"cell_type":"code","source":"# Filtering rows where the spot price is negative\nnegative_spot_prices = merged_df[merged_df['SpotPriceEUR'] < 0]\n\n# Checking the corresponding production and consumption values\nnegative_spot_prices[['HourUTC', 'SpotPriceEUR', 'Production', 'Consumption']]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"It is evident that there are multiple instances of negative spot prices recorded alongside varying levels of electricity production and consumption.\n\nLooking at the relationship between these negative spot prices and production/consumption:\nFor the negative spot price values, the corresponding production and consumption vary widely. Some rows show high levels of production (e.g., 14140 MW production with a spot price of -11,150,000 EUR), while others show moderate consumption.\n\nThis suggests that the negative spot prices in this dataset may not necessarily be caused by the production or consumption values directly. However, the large discrepancies (such as negative values of -46 million EUR) do raise questions about potential data entry errors or anomalies.\nPotential next steps:\n\n    Data Validation: Investigate whether these extreme negative values have been correctly recorded. This might involve verifying against external sources or performing checks within the dataset (e.g., verifying values against expected ranges or correcting errors based on domain knowledge).\n    Trend Analysis: Explore if there is a pattern in these negative spot prices across time or seasons. Are they occurring during specific times (e.g., holidays or periods of high demand)?\n    Impact of Extreme Values: Analyze how these extreme spot price values influence your models and the overall analysis. If errors are confirmed, you may decide to either remove or adjust the erroneous data points.\n\nLet me know if you'd like to proceed with further analysis or exploration!","metadata":{}}]}