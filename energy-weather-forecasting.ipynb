{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3032612,"sourceType":"datasetVersion","datasetId":1854875},{"sourceId":5488073,"sourceType":"datasetVersion","datasetId":3166566},{"sourceId":10388277,"sourceType":"datasetVersion","datasetId":6435844}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Predicting Electricity Spot Prices Based on Weather Patterns in Nordic Countries**","metadata":{}},{"cell_type":"markdown","source":"In this project, I will combine weather, electricity spot price and energy productionn and consumption data for Norway in the perido of 2017-2019.\n\nhttps://www.statnett.no/en/\nhttps://www.ncdc.noaa.gov/cdo-web/\nhttps://www.energidataservice.dk/tso-electricity/Elspotprices","metadata":{}},{"cell_type":"code","source":"#Set up and Libaries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nimport plotly.express as px\n\nprint(\"Libaries imported\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.115684Z","iopub.execute_input":"2025-01-06T19:02:13.116131Z","iopub.status.idle":"2025-01-06T19:02:13.123476Z","shell.execute_reply.started":"2025-01-06T19:02:13.116101Z","shell.execute_reply":"2025-01-06T19:02:13.121920Z"}},"outputs":[{"name":"stdout","text":"Libaries imported\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"#Loading Data\nweather_df = pd.read_csv('/kaggle/input/finland-norway-and-sweden-weather-data-20152019/nordics_weather.csv')\nelectricity_df = pd.read_csv('/kaggle/input/electricity-spot-price/Elspotprices.csv', delimiter=';')\n\n# List of production and consumption CSV files.\nproduction_consumption_files = ['/kaggle/input/production-and-consumption-2017-2019/ProductionConsumption-2017.csv', \n                                '/kaggle/input/production-and-consumption-2017-2019/ProductionConsumption-2018.csv', \n                                '/kaggle/input/production-and-consumption-2017-2019/ProductionConsumption-2019.csv']\n\n# Read production and comsumption CSV files into dataframes and concatenate them together.\ndfs = [pd.read_csv(file, delimiter=';') for file in production_consumption_files]\nproduction_consumption_df = pd.concat(dfs, ignore_index=True)\n\nprint(\"Datasets Loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.125459Z","iopub.execute_input":"2025-01-06T19:02:13.125942Z","iopub.status.idle":"2025-01-06T19:02:13.294245Z","shell.execute_reply.started":"2025-01-06T19:02:13.125900Z","shell.execute_reply":"2025-01-06T19:02:13.292867Z"}},"outputs":[{"name":"stdout","text":"Datasets Loaded\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Basic exploration\nprint(weather_df.head())\nprint(weather_df.dtypes)\nprint(weather_df.isnull().sum())\n\nprint(electricity_df.head())\nprint(electricity_df.dtypes)\nprint(electricity_df.isnull().sum())\n\nprint(production_consumption_df.head())\nprint(production_consumption_df .dtypes)\nprint(production_consumption_df .isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.296476Z","iopub.execute_input":"2025-01-06T19:02:13.296992Z","iopub.status.idle":"2025-01-06T19:02:13.334418Z","shell.execute_reply.started":"2025-01-06T19:02:13.296945Z","shell.execute_reply":"2025-01-06T19:02:13.333334Z"}},"outputs":[{"name":"stdout","text":"   country      date  precipitation  snow_depth       tavg      tmax  \\\n0  Finland  1/1/2015       1.714141  284.545455   1.428571  2.912739   \n1  Finland  1/2/2015      10.016667  195.000000   0.553571  2.358599   \n2  Finland  1/3/2015       3.956061  284.294118  -1.739286  0.820382   \n3  Finland  1/4/2015       0.246193  260.772727  -7.035714 -3.110828   \n4  Finland  1/5/2015       0.036364  236.900000 -17.164286 -8.727564   \n\n        tmin  \n0  -1.015287  \n1  -0.998718  \n2  -3.463871  \n3  -9.502581  \n4 -19.004487  \ncountry           object\ndate              object\nprecipitation    float64\nsnow_depth       float64\ntavg             float64\ntmax             float64\ntmin             float64\ndtype: object\ncountry          0\ndate             0\nprecipitation    0\nsnow_depth       0\ntavg             0\ntmax             0\ntmin             0\ndtype: int64\n            HourUTC            HourDK PriceArea SpotPriceDKK SpotPriceEUR\n0  2022-10-19 21:00  2022-10-19 23:00       DK2   978,750000   131,570007\n1  2022-10-19 20:00  2022-10-19 22:00       DK2  1102,079956   148,149994\n2  2022-10-19 19:00  2022-10-19 21:00       DK2  1090,329956   146,570007\n3  2022-10-19 18:00  2022-10-19 20:00       DK2  1238,589966   166,500000\n4  2022-10-19 17:00  2022-10-19 19:00       DK2  1688,050049   226,919998\nHourUTC         object\nHourDK          object\nPriceArea       object\nSpotPriceDKK    object\nSpotPriceEUR    object\ndtype: object\nHourUTC         0\nHourDK          0\nPriceArea       0\nSpotPriceDKK    0\nSpotPriceEUR    0\ndtype: int64\n                   Time  Production  Consumption\n0  01.01.2017 00:00:00        12316        14912\n1  01.01.2017 01:00:00        12189        14786\n2  01.01.2017 02:00:00        11992        14638\n3  01.01.2017 03:00:00        11646        14442\n4  01.01.2017 04:00:00        11760        14392\nTime           object\nProduction      int64\nConsumption     int64\ndtype: object\nTime           0\nProduction     0\nConsumption    0\ndtype: int64\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"Based on the inital exploration of the datasets, we can see there are no missing values but the data structure needs to be cleaned and parsed correctly and the time zones need to be aligned.\n\nWeather Data:\nThere are no missing values and the data appears to be clean.\n\nThe 'date' column is currently type 'object', which needs to be converted to 'datetime' and set as the index. This will allow for easier time series analysis and aslignment with the other datasets.\n\nElectricity Spot Price Data:\nTherer are no missing values but the dataset requires some cleaning.\n\nThe dataframe formatting means we need to load the data with a delimiter ';'\n\nI will remove the 'SpotPriceDKK' and 'HourDK' columns due to redudency and aligning the time zones from all data sets to UTC.\n\nThe 'SpotPriceEUR' column has commas not dots in the decimal place, this will cause issues when convering them to numerical values. These converted to 'float'.\n\nThe 'HourUTC'column is a strings, which need to be converted to 'datetime' for time-based analysis just like our other datasets. I will set 'HourUTC' as the index.\n\nProduction and Conmsumption Data: ---\nThe dataframe formatting means we need to load the data with a delimiter ';'\nI also need to specify the correct formating for the date and time before converting to datetime and setting it the index.\n","metadata":{}},{"cell_type":"code","source":"#Clean Weather Dataset\n\n# Covert 'date' to 'datetime' and set 'date' as index\nweather_df['date'] = pd.to_datetime(weather_df['date'])\nweather_df.set_index('date', inplace=True)\n\nprint(weather_df.head())\nprint(weather_df.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.336118Z","iopub.execute_input":"2025-01-06T19:02:13.336496Z","iopub.status.idle":"2025-01-06T19:02:13.374957Z","shell.execute_reply.started":"2025-01-06T19:02:13.336455Z","shell.execute_reply":"2025-01-06T19:02:13.373642Z"}},"outputs":[{"name":"stdout","text":"            country  precipitation  snow_depth       tavg      tmax       tmin\ndate                                                                          \n2015-01-01  Finland       1.714141  284.545455   1.428571  2.912739  -1.015287\n2015-01-02  Finland      10.016667  195.000000   0.553571  2.358599  -0.998718\n2015-01-03  Finland       3.956061  284.294118  -1.739286  0.820382  -3.463871\n2015-01-04  Finland       0.246193  260.772727  -7.035714 -3.110828  -9.502581\n2015-01-05  Finland       0.036364  236.900000 -17.164286 -8.727564 -19.004487\ncountry           object\nprecipitation    float64\nsnow_depth       float64\ntavg             float64\ntmax             float64\ntmin             float64\ndtype: object\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"#Clean Electricity Spot Price Dataset\n\n# Convert the spot prices to numeric, handling commas and converting to float values.\nelectricity_df['SpotPriceEUR'] = electricity_df['SpotPriceEUR'].str.replace(',', '').astype(float)\n\n# Convert the 'HourUTC' column to datetime\nelectricity_df['HourUTC'] = pd.to_datetime(electricity_df['HourUTC'])\n\n# Set 'HourUTC' as index for the electricity data\nelectricity_df.set_index('HourUTC', inplace=True)\n\n# Drop the redundant columns 'SpotPriceDKK' and 'TimeDKK'\nelectricity_df = electricity_df.drop(columns=['SpotPriceDKK', 'HourDK'])\n\n\nprint(electricity_df.head())\nprint(electricity_df.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.376248Z","iopub.execute_input":"2025-01-06T19:02:13.376538Z","iopub.status.idle":"2025-01-06T19:02:13.440112Z","shell.execute_reply.started":"2025-01-06T19:02:13.376514Z","shell.execute_reply":"2025-01-06T19:02:13.438881Z"}},"outputs":[{"name":"stdout","text":"                    PriceArea  SpotPriceEUR\nHourUTC                                    \n2022-10-19 21:00:00       DK2   131570007.0\n2022-10-19 20:00:00       DK2   148149994.0\n2022-10-19 19:00:00       DK2   146570007.0\n2022-10-19 18:00:00       DK2   166500000.0\n2022-10-19 17:00:00       DK2   226919998.0\nPriceArea        object\nSpotPriceEUR    float64\ndtype: object\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Clean Production and Consumption Dataset\n\n# Strip leading/trailing spaces from the 'Time' column\nproduction_consumption_df['Time'] = production_consumption_df['Time'].str.strip()\n\n# Convert 'Time' to datetime without timezone information\nproduction_consumption_df['Time'] = pd.to_datetime(production_consumption_df['Time'], format='%d.%m.%Y %H:%M:%S')\n\n# 3. Set 'Time' as index\nproduction_consumption_df.set_index('Time', inplace=True)\n\n# Display the first few rows and the data types\nprint(production_consumption_df.head())\nprint(production_consumption_df.dtypes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.441504Z","iopub.execute_input":"2025-01-06T19:02:13.441963Z","iopub.status.idle":"2025-01-06T19:02:13.488422Z","shell.execute_reply.started":"2025-01-06T19:02:13.441920Z","shell.execute_reply":"2025-01-06T19:02:13.486315Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-23cbbb99eaf6>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Convert 'Time' to datetime using the correct format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mproduction_consumption_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduction_consumption_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%d.%m.%Y %H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 3. Set 'Time' as index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;31m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"mixed\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array_strptime_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     result, tz_parsed = objects_to_datetime64ns(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0mCall\u001b[0m \u001b[0marray_strptime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mfallback\u001b[0m \u001b[0mbehavior\u001b[0m \u001b[0mdepending\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m'errors'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \"\"\"\n\u001b[0;32m--> 519\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimezones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_strptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimezones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_return_parsed_timezone_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimezones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mstrptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n","\u001b[0;32mstrptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: unconverted data remains when parsing with format \"%d.%m.%Y %H:%M:%S\": \" +02:00\", at position 2018. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."],"ename":"ValueError","evalue":"unconverted data remains when parsing with format \"%d.%m.%Y %H:%M:%S\": \" +02:00\", at position 2018. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.","output_type":"error"}],"execution_count":34},{"cell_type":"markdown","source":"There is an overlaping time frame from 2017 to 2019 which will be where I merge the two data sets for futher analysis.","metadata":{}},{"cell_type":"code","source":"# Filter the datasets to match the time range of (2017-2019)\nweather_df_filtered = weather_df[\n    (weather_df.index >= '2017-01-01') & (weather_df.index <= '2019-12-31')\n]\nelectricity_df_filtered = electricity_df[\n    (electricity_df.index >= '2017-01-01') & (electricity_df.index <= '2019-12-31')\n]\n\nproduction_consumption_df_filtered = production_consumption_df[\n    (production_consumption_df.index >= '2017-01-01') & (production_consumption_df.index <= '2019-12-31')\n]\n\n# Merge the datasets on the 'HourUTC' column (adjust if merging on other columns)\nmerged_df = pd.merge(electricity_df_filtered, weather_df_filtered, left_on='HourUTC', right_index=True, how='inner')\n\n# Display the first few rows of the merged dataframe\nprint(merged_df.head())\nprint(merged_df.dtypes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.489168Z","iopub.status.idle":"2025-01-06T19:02:13.489490Z","shell.execute_reply":"2025-01-06T19:02:13.489367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove duplicates (if any)\nmerged_df = merged_df.drop_duplicates()\n\n# Reset the index for easier manipulation\nmerged_df.reset_index(inplace=True)\n\n#merged_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n\n# Visualize relationships between electricity prices and weather variables\n#plt.figure(figsize=(10, 6))\n#sns.lineplot(x='HourUTC', y='SpotPriceDKK', data=merged_df, label='DKK Price')\n#sns.lineplot(x='HourUTC', y='tavg', data=merged_df, label='Avg Temp')\n#plt.title('Electricity Spot Price and Average Temperature Over Time')\n#plt.xlabel('Date')\n#plt.ylabel('Values')\n#plt.legend()\n#plt.show()\n\n# Explore correlations\n#corr = merged_df[['SpotPriceDKK', 'SpotPriceEUR', 'precipitation', 'snow_depth', 'tavg', 'tmax', 'tmin']].corr()\n#sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n#plt.title('Correlation Matrix')\n#plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.490259Z","iopub.status.idle":"2025-01-06T19:02:13.490565Z","shell.execute_reply":"2025-01-06T19:02:13.490436Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define X (features) and y (target)\nX = merged_df[['precipitation', 'snow_depth', 'tavg', 'tmax', 'tmin']]  # You can add more features\ny = merged_df['SpotPriceDKK']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train a regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict and evaluate\ny_pred = model.predict(X_test)\nprint(\"Mean Absolute Error: \", mean_absolute_error(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.491495Z","iopub.status.idle":"2025-01-06T19:02:13.491863Z","shell.execute_reply":"2025-01-06T19:02:13.491692Z"}},"outputs":[],"execution_count":null}]}