{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3032612,"sourceType":"datasetVersion","datasetId":1854875},{"sourceId":5488073,"sourceType":"datasetVersion","datasetId":3166566},{"sourceId":10388277,"sourceType":"datasetVersion","datasetId":6435844}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Predicting Electricity Spot Prices Based on Weather Patterns in Nordic Countries**","metadata":{}},{"cell_type":"markdown","source":"In this project, I will combine weather, electricity spot price and energy productionn and consumption data for Norway in the perido of 2017-2019.\n\nhttps://www.statnett.no/en/\nhttps://www.ncdc.noaa.gov/cdo-web/\nhttps://www.energidataservice.dk/tso-electricity/Elspotprices","metadata":{}},{"cell_type":"code","source":"#Set up and Libaries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nimport plotly.express as px\n\nprint(\"Libaries imported\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.115684Z","iopub.execute_input":"2025-01-06T19:02:13.116131Z","iopub.status.idle":"2025-01-06T19:02:13.123476Z","shell.execute_reply.started":"2025-01-06T19:02:13.116101Z","shell.execute_reply":"2025-01-06T19:02:13.121920Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Loading Data\nweather_df = pd.read_csv('/kaggle/input/finland-norway-and-sweden-weather-data-20152019/nordics_weather.csv')\nelectricity_df = pd.read_csv('/kaggle/input/electricity-spot-price/Elspotprices.csv', delimiter=';')\n\n# List of production and consumption CSV files.\nproduction_consumption_files = ['/kaggle/input/production-and-consumption2017-2019/ProductionConsumption-2017.csv', \n                                '/kaggle/input/production-and-consumption2017-2019/ProductionConsumption-2018.csv', \n                                '/kaggle/input/production-and-consumption2017-2019/ProductionConsumption-2019.csv']\n\n# Read production and comsumption CSV files into dataframes and concatenate them together.\ndfs = [pd.read_csv(file, delimiter=';') for file in production_consumption_files]\nproduction_consumption_df = pd.concat(dfs, ignore_index=True)\n\nprint(\"Datasets Loaded\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.125459Z","iopub.execute_input":"2025-01-06T19:02:13.125942Z","iopub.status.idle":"2025-01-06T19:02:13.294245Z","shell.execute_reply.started":"2025-01-06T19:02:13.125900Z","shell.execute_reply":"2025-01-06T19:02:13.292867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Basic exploration\nprint(weather_df.head())\nprint(weather_df.dtypes)\nprint(weather_df.isnull().sum())\n\nprint(electricity_df.head())\nprint(electricity_df.dtypes)\nprint(electricity_df.isnull().sum())\n\nprint(production_consumption_df.head())\nprint(production_consumption_df .dtypes)\nprint(production_consumption_df .isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.296476Z","iopub.execute_input":"2025-01-06T19:02:13.296992Z","iopub.status.idle":"2025-01-06T19:02:13.334418Z","shell.execute_reply.started":"2025-01-06T19:02:13.296945Z","shell.execute_reply":"2025-01-06T19:02:13.333334Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Based on the inital exploration of the datasets, we can see there are no missing values but the data structure needs to be cleaned and parsed correctly and the time zones need to be aligned.\n\nWeather Data:\nThere are no missing values and the data appears to be clean.\n\nThe 'date' column is currently type 'object', which needs to be converted to 'datetime' and set as the index. This will allow for easier time series analysis and aslignment with the other datasets.\n\nElectricity Spot Price Data:\nTherer are no missing values but the dataset requires some cleaning.\n\nThe dataframe formatting means we need to load the data with a delimiter ';'\n\nI will remove the 'SpotPriceDKK' and 'HourDK' columns due to redudency and aligning the time zones from all data sets to UTC.\n\nThe 'SpotPriceEUR' column has commas not dots in the decimal place, this will cause issues when convering them to numerical values. These converted to 'float'.\n\nThe 'HourUTC'column is a strings, which need to be converted to 'datetime' for time-based analysis just like our other datasets. I will set 'HourUTC' as the index.\n\nProduction and Conmsumption Data: ---\nThe dataframe formatting means we need to load the data with a delimiter ';'\nI also need to specify the correct formating for the date and time before converting to datetime and setting it the index.\n","metadata":{}},{"cell_type":"code","source":"#Clean Weather Dataset\n\n# Covert 'date' to 'datetime' and set 'date' as index\nweather_df['date'] = pd.to_datetime(weather_df['date'])\nweather_df.set_index('date', inplace=True)\n\nprint(weather_df.head())\nprint(weather_df.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.336118Z","iopub.execute_input":"2025-01-06T19:02:13.336496Z","iopub.status.idle":"2025-01-06T19:02:13.374957Z","shell.execute_reply.started":"2025-01-06T19:02:13.336455Z","shell.execute_reply":"2025-01-06T19:02:13.373642Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Clean Electricity Spot Price Dataset\n\n# Convert the spot prices to numeric, handling commas and converting to float values.\nelectricity_df['SpotPriceEUR'] = electricity_df['SpotPriceEUR'].str.replace(',', '').astype(float)\n\n# Convert the 'HourUTC' column to datetime\nelectricity_df['HourUTC'] = pd.to_datetime(electricity_df['HourUTC'])\n\n# Set 'HourUTC' as index for the electricity data\nelectricity_df.set_index('HourUTC', inplace=True)\n\n# Drop the redundant columns 'SpotPriceDKK' and 'TimeDKK'\nelectricity_df = electricity_df.drop(columns=['SpotPriceDKK', 'HourDK'])\n\n\nprint(electricity_df.head())\nprint(electricity_df.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.376248Z","iopub.execute_input":"2025-01-06T19:02:13.376538Z","iopub.status.idle":"2025-01-06T19:02:13.440112Z","shell.execute_reply.started":"2025-01-06T19:02:13.376514Z","shell.execute_reply":"2025-01-06T19:02:13.438881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Clean Production and Consumption Dataset\n\n# Strip leading/trailing spaces from the 'Time' column\nproduction_consumption_df['Time'] = production_consumption_df['Time'].str.strip()\n\n# Convert 'Time' to datetime without timezone information\nproduction_consumption_df['Time'] = pd.to_datetime(production_consumption_df['Time'], format='%d.%m.%Y %H:%M:%S')\n\n# 3. Set 'Time' as index\nproduction_consumption_df.set_index('Time', inplace=True)\n\n# Display the first few rows and the data types\nprint(production_consumption_df.head())\nprint(production_consumption_df.dtypes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.441504Z","iopub.execute_input":"2025-01-06T19:02:13.441963Z","iopub.status.idle":"2025-01-06T19:02:13.488422Z","shell.execute_reply.started":"2025-01-06T19:02:13.441920Z","shell.execute_reply":"2025-01-06T19:02:13.486315Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There is an overlaping time frame from 2017 to 2019 which will be where I merge the two data sets for futher analysis.","metadata":{}},{"cell_type":"code","source":"# Filter the datasets to match the time range of (2017-2019)\nweather_df_filtered = weather_df[\n    (weather_df.index >= '2017-01-01') & (weather_df.index <= '2019-12-31')\n]\nelectricity_df_filtered = electricity_df[\n    (electricity_df.index >= '2017-01-01') & (electricity_df.index <= '2019-12-31')\n]\n\nproduction_consumption_df_filtered = production_consumption_df[\n    (production_consumption_df.index >= '2017-01-01') & (production_consumption_df.index <= '2019-12-31')\n]\n\n# Merge the datasets on the 'HourUTC' column (adjust if merging on other columns)\nmerged_df = pd.merge(electricity_df_filtered, weather_df_filtered, left_on='HourUTC', right_index=True, how='inner')\n\n# Display the first few rows of the merged dataframe\nprint(merged_df.head())\nprint(merged_df.dtypes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.489168Z","iopub.status.idle":"2025-01-06T19:02:13.489490Z","shell.execute_reply":"2025-01-06T19:02:13.489367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove duplicates (if any)\nmerged_df = merged_df.drop_duplicates()\n\n# Reset the index for easier manipulation\nmerged_df.reset_index(inplace=True)\n\n#merged_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n\n# Visualize relationships between electricity prices and weather variables\n#plt.figure(figsize=(10, 6))\n#sns.lineplot(x='HourUTC', y='SpotPriceDKK', data=merged_df, label='DKK Price')\n#sns.lineplot(x='HourUTC', y='tavg', data=merged_df, label='Avg Temp')\n#plt.title('Electricity Spot Price and Average Temperature Over Time')\n#plt.xlabel('Date')\n#plt.ylabel('Values')\n#plt.legend()\n#plt.show()\n\n# Explore correlations\n#corr = merged_df[['SpotPriceDKK', 'SpotPriceEUR', 'precipitation', 'snow_depth', 'tavg', 'tmax', 'tmin']].corr()\n#sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n#plt.title('Correlation Matrix')\n#plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.490259Z","iopub.status.idle":"2025-01-06T19:02:13.490565Z","shell.execute_reply":"2025-01-06T19:02:13.490436Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define X (features) and y (target)\nX = merged_df[['precipitation', 'snow_depth', 'tavg', 'tmax', 'tmin']]  # You can add more features\ny = merged_df['SpotPriceDKK']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train a regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict and evaluate\ny_pred = model.predict(X_test)\nprint(\"Mean Absolute Error: \", mean_absolute_error(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T19:02:13.491495Z","iopub.status.idle":"2025-01-06T19:02:13.491863Z","shell.execute_reply":"2025-01-06T19:02:13.491692Z"}},"outputs":[],"execution_count":null}]}