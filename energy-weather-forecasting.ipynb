{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2833f5a3",
   "metadata": {
    "papermill": {
     "duration": 0.002909,
     "end_time": "2025-01-05T12:16:43.341458",
     "exception": false,
     "start_time": "2025-01-05T12:16:43.338549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Predicting Electricity Spot Prices Based on Weather Patterns in Nordic Countries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9721ac",
   "metadata": {
    "papermill": {
     "duration": 0.001994,
     "end_time": "2025-01-05T12:16:43.346097",
     "exception": false,
     "start_time": "2025-01-05T12:16:43.344103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this project, we will combine historical weather data and electricity spot price data for the years 2015-2019 in Finland, Norway, and Sweden. Our goal is to predict the electricity spot prices by using weather features like temperature, precipitation, and wind speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e70a596",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-05T12:16:43.351834Z",
     "iopub.status.busy": "2025-01-05T12:16:43.351494Z",
     "iopub.status.idle": "2025-01-05T12:16:45.827540Z",
     "shell.execute_reply": "2025-01-05T12:16:45.826388Z"
    },
    "papermill": {
     "duration": 2.480957,
     "end_time": "2025-01-05T12:16:45.829216",
     "exception": false,
     "start_time": "2025-01-05T12:16:43.348259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libaries imported\n"
     ]
    }
   ],
   "source": [
    "#Set up and Libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import plotly.express as px\n",
    "\n",
    "print(\"Libaries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba299120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T12:16:45.835649Z",
     "iopub.status.busy": "2025-01-05T12:16:45.835136Z",
     "iopub.status.idle": "2025-01-05T12:16:46.053296Z",
     "shell.execute_reply": "2025-01-05T12:16:46.052259Z"
    },
    "papermill": {
     "duration": 0.223198,
     "end_time": "2025-01-05T12:16:46.055036",
     "exception": false,
     "start_time": "2025-01-05T12:16:45.831838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets Loaded\n"
     ]
    }
   ],
   "source": [
    "#Loading Data\n",
    "weather_df = pd.read_csv('/kaggle/input/finland-norway-and-sweden-weather-data-20152019/nordics_weather.csv')\n",
    "electricity_df = pd.read_csv('/kaggle/input/electricity-spot-price/Elspotprices.csv')\n",
    "\n",
    "print(\"Datasets Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e23b6e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T12:16:46.061292Z",
     "iopub.status.busy": "2025-01-05T12:16:46.060992Z",
     "iopub.status.idle": "2025-01-05T12:16:46.098272Z",
     "shell.execute_reply": "2025-01-05T12:16:46.096853Z"
    },
    "papermill": {
     "duration": 0.042223,
     "end_time": "2025-01-05T12:16:46.099936",
     "exception": false,
     "start_time": "2025-01-05T12:16:46.057713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5478 entries, 0 to 5477\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   country        5478 non-null   object \n",
      " 1   date           5478 non-null   object \n",
      " 2   precipitation  5478 non-null   float64\n",
      " 3   snow_depth     5478 non-null   float64\n",
      " 4   tavg           5478 non-null   float64\n",
      " 5   tmax           5478 non-null   float64\n",
      " 6   tmin           5478 non-null   float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 299.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 50831 entries, ('2022-10-19 21:00;2022-10-19 23:00;DK2;978', '750000;131') to ('2016-12-31 23:00;2017-01-01 00:00;DK2;155', '820007;20')\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                              Non-Null Count  Dtype\n",
      "---  ------                                              --------------  -----\n",
      " 0   HourUTC;HourDK;PriceArea;SpotPriceDKK;SpotPriceEUR  50831 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 3.7+ MB\n",
      "   country      date  precipitation  snow_depth       tavg      tmax  \\\n",
      "0  Finland  1/1/2015       1.714141  284.545455   1.428571  2.912739   \n",
      "1  Finland  1/2/2015      10.016667  195.000000   0.553571  2.358599   \n",
      "2  Finland  1/3/2015       3.956061  284.294118  -1.739286  0.820382   \n",
      "3  Finland  1/4/2015       0.246193  260.772727  -7.035714 -3.110828   \n",
      "4  Finland  1/5/2015       0.036364  236.900000 -17.164286 -8.727564   \n",
      "\n",
      "        tmin  \n",
      "0  -1.015287  \n",
      "1  -0.998718  \n",
      "2  -3.463871  \n",
      "3  -9.502581  \n",
      "4 -19.004487  \n",
      "                                                       HourUTC;HourDK;PriceArea;SpotPriceDKK;SpotPriceEUR\n",
      "2022-10-19 21:00;2022-10-19 23:00;DK2;978  750000;131                                             570007 \n",
      "2022-10-19 20:00;2022-10-19 22:00;DK2;1102 079956;148                                             149994 \n",
      "2022-10-19 19:00;2022-10-19 21:00;DK2;1090 329956;146                                             570007 \n",
      "2022-10-19 18:00;2022-10-19 20:00;DK2;1238 589966;166                                             500000 \n",
      "2022-10-19 17:00;2022-10-19 19:00;DK2;1688 050049;226                                             919998 \n"
     ]
    }
   ],
   "source": [
    "#Inital Data Exploration\n",
    "weather_df.head()\n",
    "electricity_df.head()\n",
    "\n",
    "weather_df.info()\n",
    "electricity_df.info()\n",
    "\n",
    "weather_df.isnull().sum()\n",
    "electricity_df.isnull().sum()\n",
    "\n",
    "\n",
    "print(weather_df.head())\n",
    "print(electricity_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9a5f0a",
   "metadata": {
    "papermill": {
     "duration": 0.002364,
     "end_time": "2025-01-05T12:16:46.105175",
     "exception": false,
     "start_time": "2025-01-05T12:16:46.102811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Based on the inital exploration of both datasets, we can see there are no missing values but the data structure needs to be cleaned and parsed correctly\n",
    "\n",
    "Weather Data:\n",
    "There are no missing values and the data appears to be clean.\n",
    "\n",
    "The 'date' column is currently type object, which needs to be converted to 'datetime' and set as the iundex. This will allow for easier time series analysis and aslignment with the Electricity Spot Price Dataset\n",
    "\n",
    "Electricity Spot Price Data:\n",
    "Therer are no missing values but the dataset requires some cleaning.\n",
    "\n",
    "The column formatting is currently a single column with concatenated values. These need to be split and orangized into seperate columns.\n",
    "\n",
    "The 'SpotPriceDKK' and 'SpotPriceEUR' columns have commas not dots in the decimal place, this will cause issues when convering them to numerical values. These will be cleanded and converted to 'float'.\n",
    "\n",
    "Both 'HourUTC' and 'HourDK' columns are strings which need to be converted to 'datetime' for time-based analysis just like our weather 'data' values. I will set 'HourUTC' as the index as this will allow me to merge the datesend on a common index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3afa4f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T12:16:46.111288Z",
     "iopub.status.busy": "2025-01-05T12:16:46.110900Z",
     "iopub.status.idle": "2025-01-05T12:16:46.138120Z",
     "shell.execute_reply": "2025-01-05T12:16:46.137032Z"
    },
    "papermill": {
     "duration": 0.031893,
     "end_time": "2025-01-05T12:16:46.139542",
     "exception": false,
     "start_time": "2025-01-05T12:16:46.107649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            country  precipitation  snow_depth       tavg      tmax       tmin\n",
      "date                                                                          \n",
      "2015-01-01  Finland       1.714141  284.545455   1.428571  2.912739  -1.015287\n",
      "2015-01-02  Finland      10.016667  195.000000   0.553571  2.358599  -0.998718\n",
      "2015-01-03  Finland       3.956061  284.294118  -1.739286  0.820382  -3.463871\n",
      "2015-01-04  Finland       0.246193  260.772727  -7.035714 -3.110828  -9.502581\n",
      "2015-01-05  Finland       0.036364  236.900000 -17.164286 -8.727564 -19.004487\n"
     ]
    }
   ],
   "source": [
    "#Weather Dataset\n",
    "\n",
    "# Covert 'date' to 'datetime' and set 'date' as index\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "weather_df.set_index('date', inplace=True)\n",
    "\n",
    "print(weather_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74aa399e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T12:16:46.146329Z",
     "iopub.status.busy": "2025-01-05T12:16:46.146022Z",
     "iopub.status.idle": "2025-01-05T12:16:50.096252Z",
     "shell.execute_reply": "2025-01-05T12:16:50.095097Z"
    },
    "papermill": {
     "duration": 3.955505,
     "end_time": "2025-01-05T12:16:50.098004",
     "exception": false,
     "start_time": "2025-01-05T12:16:46.142499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with incorrect splits (less than 5 values):\n",
      "Series([], dtype: int64)\n",
      "                                                            0\n",
      "2022-10-19 21:00;2022-10-19 23:00;DK2;978  750000;131  570007\n",
      "2022-10-19 20:00;2022-10-19 22:00;DK2;1102 079956;148  149994\n",
      "2022-10-19 19:00;2022-10-19 21:00;DK2;1090 329956;146  570007\n",
      "2022-10-19 18:00;2022-10-19 20:00;DK2;1238 589966;166  500000\n",
      "2022-10-19 17:00;2022-10-19 19:00;DK2;1688 050049;226  919998\n",
      "Split did not produce 5 columns. Please check the data for inconsistencies.\n"
     ]
    }
   ],
   "source": [
    "#Electricity Spot Price Dataset\n",
    "\n",
    "# Step 1: Ensure the column is of string type\n",
    "electricity_df['HourUTC;HourDK;PriceArea;SpotPriceDKK;SpotPriceEUR'] = electricity_df['HourUTC;HourDK;PriceArea;SpotPriceDKK;SpotPriceEUR'].astype(str)\n",
    "\n",
    "# Step 2: Clean extra spaces and multiple semicolons\n",
    "# Normalize spaces and ensure only one semicolon between values\n",
    "electricity_df['HourUTC;HourDK;PriceArea;SpotPriceDKK;SpotPriceEUR'] = (\n",
    "    electricity_df['HourUTC;HourDK;PriceArea;SpotPriceDKK;SpotPriceEUR']\n",
    "    .str.replace(r'\\s+', ' ', regex=True)   # Replace multiple spaces with a single space\n",
    "    .str.replace(r';\\s*', ';', regex=True)  # Ensure semicolons are followed by no spaces\n",
    "    .str.replace(r'\\s*;', ';', regex=True)  # Ensure semicolons are preceded by no spaces\n",
    ")\n",
    "\n",
    "# Step 3: Check how many splits each row produces\n",
    "split_data = electricity_df['HourUTC;HourDK;PriceArea;SpotPriceDKK;SpotPriceEUR'].str.split(';', expand=True)\n",
    "\n",
    "# Step 4: Print the number of splits for each row to check for anomalies\n",
    "split_counts = split_data.apply(lambda row: row.isnull().sum(), axis=1)  # Counts rows that failed to split\n",
    "print(\"Rows with incorrect splits (less than 5 values):\")\n",
    "print(split_counts[split_counts > 0])\n",
    "\n",
    "# Step 5: Check the first few rows to inspect how the split is working\n",
    "print(split_data.head())\n",
    "\n",
    "# Step 6: Handle the case if the split is successful\n",
    "if split_data.shape[1] == 5:\n",
    "    # Rename the columns\n",
    "    split_data.columns = ['HourUTC', 'HourDK', 'PriceArea', 'SpotPriceDKK', 'SpotPriceEUR']\n",
    "    \n",
    "    # Step 7: Merge the split columns back to the original dataframe\n",
    "    electricity_df = electricity_df.join(split_data)\n",
    "\n",
    "    # Remove the original concatenated column\n",
    "    electricity_df.drop(columns=['HourUTC;HourDK;PriceArea;SpotPriceDKK;SpotPriceEUR'], inplace=True)\n",
    "\n",
    "    # Step 8: Clean and convert SpotPrice columns\n",
    "    electricity_df['SpotPriceDKK'] = electricity_df['SpotPriceDKK'].str.replace(',', '.').astype(float)\n",
    "    electricity_df['SpotPriceEUR'] = electricity_df['SpotPriceEUR'].str.replace(',', '.').astype(float)\n",
    "\n",
    "    # Step 9: Convert HourUTC and HourDK to datetime\n",
    "    electricity_df['HourUTC'] = pd.to_datetime(electricity_df['HourUTC'])\n",
    "    electricity_df['HourDK'] = pd.to_datetime(electricity_df['HourDK'])\n",
    "\n",
    "    # Step 10: Set 'HourUTC' as the index\n",
    "    electricity_df.set_index('HourUTC', inplace=True)\n",
    "\n",
    "    # Verify the cleaned dataframe\n",
    "    print(electricity_df.head())\n",
    "\n",
    "else:\n",
    "    print(\"Split did not produce 5 columns. Please check the data for inconsistencies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c2997a",
   "metadata": {
    "papermill": {
     "duration": 0.002642,
     "end_time": "2025-01-05T12:16:50.103792",
     "exception": false,
     "start_time": "2025-01-05T12:16:50.101150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Handling Missing Values\n",
    "Based on the two data sets in this poroject its important to handle missing values independatly. For the weather dataset, theere"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1854875,
     "sourceId": 3032612,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3166566,
     "sourceId": 5488073,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.605072,
   "end_time": "2025-01-05T12:16:50.825818",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-05T12:16:41.220746",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
