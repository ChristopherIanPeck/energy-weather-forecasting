{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "501b5401",
   "metadata": {
    "papermill": {
     "duration": 0.00362,
     "end_time": "2025-01-09T16:15:46.062926",
     "exception": false,
     "start_time": "2025-01-09T16:15:46.059306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Predicting Electricity Spot Prices Based on Weather Patterns in Nordic Countries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24423004",
   "metadata": {
    "papermill": {
     "duration": 0.002679,
     "end_time": "2025-01-09T16:15:46.068989",
     "exception": false,
     "start_time": "2025-01-09T16:15:46.066310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this project, I will combine weather, electricity spot price and energy productionn and consumption data for Norway in the perido of 2017-2019.\n",
    "\n",
    "https://www.statnett.no/en/\n",
    "https://www.ncdc.noaa.gov/cdo-web/\n",
    "https://www.energidataservice.dk/tso-electricity/Elspotprices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6d5bab",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-09T16:15:46.076317Z",
     "iopub.status.busy": "2025-01-09T16:15:46.075940Z",
     "iopub.status.idle": "2025-01-09T16:15:49.388995Z",
     "shell.execute_reply": "2025-01-09T16:15:49.387585Z"
    },
    "papermill": {
     "duration": 3.319136,
     "end_time": "2025-01-09T16:15:49.391099",
     "exception": false,
     "start_time": "2025-01-09T16:15:46.071963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libaries imported\n"
     ]
    }
   ],
   "source": [
    "#Set up and Libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import plotly.express as px\n",
    "\n",
    "print(\"Libaries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ab0ae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:15:49.399295Z",
     "iopub.status.busy": "2025-01-09T16:15:49.398570Z",
     "iopub.status.idle": "2025-01-09T16:15:49.707897Z",
     "shell.execute_reply": "2025-01-09T16:15:49.706735Z"
    },
    "papermill": {
     "duration": 0.315099,
     "end_time": "2025-01-09T16:15:49.709569",
     "exception": false,
     "start_time": "2025-01-09T16:15:49.394470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets Loaded\n"
     ]
    }
   ],
   "source": [
    "#Loading Data\n",
    "weather_df = pd.read_csv('/kaggle/input/finland-norway-and-sweden-weather-data-20152019/nordics_weather.csv')\n",
    "electricity_df = pd.read_csv('/kaggle/input/electricity-spot-price/Elspotprices.csv', delimiter=';')\n",
    "\n",
    "# List of production and consumption CSV files.\n",
    "production_consumption_files = ['/kaggle/input/production-and-consumption2017-2019/ProductionConsumption-2017.csv', \n",
    "                                '/kaggle/input/production-and-consumption2017-2019/ProductionConsumption-2018.csv', \n",
    "                                '/kaggle/input/production-and-consumption2017-2019/ProductionConsumption-2019.csv']\n",
    "\n",
    "# Read production and comsumption CSV files into dataframes and concatenate them together.\n",
    "dfs = [pd.read_csv(file, delimiter=';') for file in production_consumption_files]\n",
    "production_consumption_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(\"Datasets Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fc9b68d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:15:49.718085Z",
     "iopub.status.busy": "2025-01-09T16:15:49.717685Z",
     "iopub.status.idle": "2025-01-09T16:15:49.765205Z",
     "shell.execute_reply": "2025-01-09T16:15:49.763782Z"
    },
    "papermill": {
     "duration": 0.054101,
     "end_time": "2025-01-09T16:15:49.767000",
     "exception": false,
     "start_time": "2025-01-09T16:15:49.712899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   country      date  precipitation  snow_depth       tavg      tmax  \\\n",
      "0  Finland  1/1/2015       1.714141  284.545455   1.428571  2.912739   \n",
      "1  Finland  1/2/2015      10.016667  195.000000   0.553571  2.358599   \n",
      "2  Finland  1/3/2015       3.956061  284.294118  -1.739286  0.820382   \n",
      "3  Finland  1/4/2015       0.246193  260.772727  -7.035714 -3.110828   \n",
      "4  Finland  1/5/2015       0.036364  236.900000 -17.164286 -8.727564   \n",
      "\n",
      "        tmin  \n",
      "0  -1.015287  \n",
      "1  -0.998718  \n",
      "2  -3.463871  \n",
      "3  -9.502581  \n",
      "4 -19.004487  \n",
      "country           object\n",
      "date              object\n",
      "precipitation    float64\n",
      "snow_depth       float64\n",
      "tavg             float64\n",
      "tmax             float64\n",
      "tmin             float64\n",
      "dtype: object\n",
      "country          0\n",
      "date             0\n",
      "precipitation    0\n",
      "snow_depth       0\n",
      "tavg             0\n",
      "tmax             0\n",
      "tmin             0\n",
      "dtype: int64\n",
      "            HourUTC            HourDK PriceArea SpotPriceDKK SpotPriceEUR\n",
      "0  2022-10-19 21:00  2022-10-19 23:00       DK2   978,750000   131,570007\n",
      "1  2022-10-19 20:00  2022-10-19 22:00       DK2  1102,079956   148,149994\n",
      "2  2022-10-19 19:00  2022-10-19 21:00       DK2  1090,329956   146,570007\n",
      "3  2022-10-19 18:00  2022-10-19 20:00       DK2  1238,589966   166,500000\n",
      "4  2022-10-19 17:00  2022-10-19 19:00       DK2  1688,050049   226,919998\n",
      "HourUTC         object\n",
      "HourDK          object\n",
      "PriceArea       object\n",
      "SpotPriceDKK    object\n",
      "SpotPriceEUR    object\n",
      "dtype: object\n",
      "HourUTC         0\n",
      "HourDK          0\n",
      "PriceArea       0\n",
      "SpotPriceDKK    0\n",
      "SpotPriceEUR    0\n",
      "dtype: int64\n",
      "               Time  Production  Consumption\n",
      "0  2017-01-01 00:00       12316        14912\n",
      "1  2017-01-01 01:00       12189        14786\n",
      "2  2017-01-01 02:00       11992        14638\n",
      "3  2017-01-01 03:00       11646        14442\n",
      "4  2017-01-01 04:00       11760        14392\n",
      "Time           object\n",
      "Production      int64\n",
      "Consumption     int64\n",
      "dtype: object\n",
      "Time           0\n",
      "Production     0\n",
      "Consumption    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Basic exploration\n",
    "print(weather_df.head())\n",
    "print(weather_df.dtypes)\n",
    "print(weather_df.isnull().sum())\n",
    "\n",
    "print(electricity_df.head())\n",
    "print(electricity_df.dtypes)\n",
    "print(electricity_df.isnull().sum())\n",
    "\n",
    "print(production_consumption_df.head())\n",
    "print(production_consumption_df .dtypes)\n",
    "print(production_consumption_df .isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d533106",
   "metadata": {
    "papermill": {
     "duration": 0.003073,
     "end_time": "2025-01-09T16:15:49.773545",
     "exception": false,
     "start_time": "2025-01-09T16:15:49.770472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Based on the inital exploration of the datasets, we can see there are no missing values but the data structure needs to be cleaned and parsed correctly and the time zones need to be aligned.\n",
    "\n",
    "Weather Data:\n",
    "There are no missing values and the data appears to be clean.\n",
    "\n",
    "The 'date' column is currently type 'object', which needs to be converted to 'datetime' and set as the index. This will allow for easier time series analysis and aslignment with the other datasets.\n",
    "\n",
    "Electricity Spot Price Data:\n",
    "Therer are no missing values but the dataset requires some cleaning.\n",
    "\n",
    "The dataframe formatting means we need to load the data with a delimiter ';'\n",
    "\n",
    "I will remove the 'SpotPriceDKK', 'HourDK' and 'PriceArea' columns due to redudency.\n",
    "\n",
    "The 'SpotPriceEUR' column has commas not dots in the decimal place, this will cause issues when convering them to numerical values. These converted to 'float'.\n",
    "\n",
    "The 'HourUTC'column is a strings, which need to be converted to 'datetime' for time-based analysis just like our other datasets. I will set 'HourUTC' as the index.\n",
    "\n",
    "Production and Conmsumption Data: ---\n",
    "The dataframe formatting means we need to load the data with a delimiter ';'\n",
    "I also need to specify the correct formating for the date and time before converting to datetime and setting it the index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6551c312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:15:49.781469Z",
     "iopub.status.busy": "2025-01-09T16:15:49.781128Z",
     "iopub.status.idle": "2025-01-09T16:15:49.812252Z",
     "shell.execute_reply": "2025-01-09T16:15:49.810969Z"
    },
    "papermill": {
     "duration": 0.037131,
     "end_time": "2025-01-09T16:15:49.813995",
     "exception": false,
     "start_time": "2025-01-09T16:15:49.776864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            country  precipitation  snow_depth       tavg      tmax       tmin\n",
      "date                                                                          \n",
      "2015-01-01  Finland       1.714141  284.545455   1.428571  2.912739  -1.015287\n",
      "2015-01-02  Finland      10.016667  195.000000   0.553571  2.358599  -0.998718\n",
      "2015-01-03  Finland       3.956061  284.294118  -1.739286  0.820382  -3.463871\n",
      "2015-01-04  Finland       0.246193  260.772727  -7.035714 -3.110828  -9.502581\n",
      "2015-01-05  Finland       0.036364  236.900000 -17.164286 -8.727564 -19.004487\n",
      "country           object\n",
      "precipitation    float64\n",
      "snow_depth       float64\n",
      "tavg             float64\n",
      "tmax             float64\n",
      "tmin             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Clean Weather Dataset\n",
    "\n",
    "# Covert 'date' to 'datetime' and set 'date' as index\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "weather_df.set_index('date', inplace=True)\n",
    "\n",
    "print(weather_df.head())\n",
    "print(weather_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98bfaad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:15:49.822272Z",
     "iopub.status.busy": "2025-01-09T16:15:49.821929Z",
     "iopub.status.idle": "2025-01-09T16:15:49.883249Z",
     "shell.execute_reply": "2025-01-09T16:15:49.881767Z"
    },
    "papermill": {
     "duration": 0.067894,
     "end_time": "2025-01-09T16:15:49.885428",
     "exception": false,
     "start_time": "2025-01-09T16:15:49.817534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     SpotPriceEUR\n",
      "HourUTC                          \n",
      "2022-10-19 21:00:00   131570007.0\n",
      "2022-10-19 20:00:00   148149994.0\n",
      "2022-10-19 19:00:00   146570007.0\n",
      "2022-10-19 18:00:00   166500000.0\n",
      "2022-10-19 17:00:00   226919998.0\n",
      "SpotPriceEUR    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Clean Electricity Spot Price Dataset\n",
    "\n",
    "# Convert the spot prices to numeric, handling commas and converting to float values.\n",
    "electricity_df['SpotPriceEUR'] = electricity_df['SpotPriceEUR'].str.replace(',', '').astype(float)\n",
    "\n",
    "# Convert the 'HourUTC' column to datetime\n",
    "electricity_df['HourUTC'] = pd.to_datetime(electricity_df['HourUTC'])\n",
    "\n",
    "# Set 'HourUTC' as index for the electricity data\n",
    "electricity_df.set_index('HourUTC', inplace=True)\n",
    "\n",
    "# Drop the redundant columns 'SpotPriceDKK' and 'TimeDKK'\n",
    "electricity_df = electricity_df.drop(columns=['SpotPriceDKK', 'HourDK', 'PriceArea'])\n",
    "\n",
    "\n",
    "print(electricity_df.head())\n",
    "print(electricity_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb8815fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:15:49.894105Z",
     "iopub.status.busy": "2025-01-09T16:15:49.893669Z",
     "iopub.status.idle": "2025-01-09T16:15:49.913668Z",
     "shell.execute_reply": "2025-01-09T16:15:49.912316Z"
    },
    "papermill": {
     "duration": 0.026397,
     "end_time": "2025-01-09T16:15:49.915519",
     "exception": false,
     "start_time": "2025-01-09T16:15:49.889122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Production  Consumption\n",
      "Time                                        \n",
      "2017-01-01 00:00:00       12316        14912\n",
      "2017-01-01 01:00:00       12189        14786\n",
      "2017-01-01 02:00:00       11992        14638\n",
      "2017-01-01 03:00:00       11646        14442\n",
      "2017-01-01 04:00:00       11760        14392\n",
      "Production     int64\n",
      "Consumption    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Clean Production and Consumption Dataset\n",
    "\n",
    "# Convert 'Time' to datetime without timezone information\n",
    "production_consumption_df['Time'] = pd.to_datetime(production_consumption_df['Time'])\n",
    "\n",
    "# 3. Set 'Time' as index\n",
    "production_consumption_df.set_index('Time', inplace=True)\n",
    "\n",
    "# Display the first few rows and the data types\n",
    "print(production_consumption_df.head())\n",
    "print(production_consumption_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5879c17",
   "metadata": {
    "papermill": {
     "duration": 0.003457,
     "end_time": "2025-01-09T16:15:49.923205",
     "exception": false,
     "start_time": "2025-01-09T16:15:49.919748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There is an overlaping time frame from 2017 to 2019 which will be where I merge the two data sets for futher analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9494fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T16:15:49.932741Z",
     "iopub.status.busy": "2025-01-09T16:15:49.932011Z",
     "iopub.status.idle": "2025-01-09T16:15:49.988056Z",
     "shell.execute_reply": "2025-01-09T16:15:49.986217Z"
    },
    "papermill": {
     "duration": 0.063071,
     "end_time": "2025-01-09T16:15:49.990105",
     "exception": false,
     "start_time": "2025-01-09T16:15:49.927034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     HourUTC  SpotPriceEUR  country  precipitation  snow_depth      tavg  \\\n",
      "0 2019-12-31    21590000.0  Finland       0.225281  124.647059 -2.859259   \n",
      "1 2019-12-31    21590000.0   Norway       4.920921  161.163158 -0.666667   \n",
      "2 2019-12-31    21590000.0   Sweden       0.848161  131.583333  1.722222   \n",
      "3 2019-12-30    11840000.0  Finland       1.229775  160.500000  2.292593   \n",
      "4 2019-12-30    11840000.0   Norway       7.822269  163.234375  1.757895   \n",
      "\n",
      "       tmax      tmin  Production  Consumption  \n",
      "0  1.580519 -6.921569       11446        15347  \n",
      "1  3.388462 -1.637500       11446        15347  \n",
      "2  4.376606 -2.290278       11446        15347  \n",
      "3  3.344156 -0.202632       11231        15318  \n",
      "4  6.254455  1.238614       11231        15318  \n",
      "HourUTC          datetime64[ns]\n",
      "SpotPriceEUR            float64\n",
      "country                  object\n",
      "precipitation           float64\n",
      "snow_depth              float64\n",
      "tavg                    float64\n",
      "tmax                    float64\n",
      "tmin                    float64\n",
      "Production                int64\n",
      "Consumption               int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Filter the datasets to match the time range of (2017-2019)\n",
    "weather_df_filtered = weather_df[\n",
    "    (weather_df.index >= '2017-01-01') & (weather_df.index <= '2019-12-31')\n",
    "]\n",
    "electricity_df_filtered = electricity_df[\n",
    "    (electricity_df.index >= '2017-01-01') & (electricity_df.index <= '2019-12-31')\n",
    "]\n",
    "production_consumption_df_filtered = production_consumption_df[\n",
    "    (production_consumption_df.index >= '2017-01-01') & (production_consumption_df.index <= '2019-12-31')\n",
    "]\n",
    "\n",
    "# Merge electricity and weather data\n",
    "merged_df_1 = pd.merge(\n",
    "    electricity_df_filtered, \n",
    "    weather_df_filtered, \n",
    "    left_on='HourUTC', \n",
    "    right_index=True, \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Merge the result with production_consumption_df\n",
    "merged_df = pd.merge(\n",
    "    merged_df_1, \n",
    "    production_consumption_df_filtered, \n",
    "    left_on='HourUTC', \n",
    "    right_index=True, \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Remove duplicates (if any)\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "\n",
    "# Reset the index for easier manipulation\n",
    "merged_df.reset_index(inplace=True)\n",
    "\n",
    "# Display the first few rows of the merged dataframe\n",
    "print(merged_df.head())\n",
    "print(merged_df.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1854875,
     "sourceId": 3032612,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3166566,
     "sourceId": 5488073,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6444667,
     "sourceId": 10401017,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.253335,
   "end_time": "2025-01-09T16:15:50.815276",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-09T16:15:43.561941",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
